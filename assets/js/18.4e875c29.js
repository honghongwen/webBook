(window.webpackJsonp=window.webpackJsonp||[]).push([[18],{273:function(s,t,a){s.exports=a.p+"assets/img/timeout_thread.a4cf80b7.png"},340:function(s,t,a){"use strict";a.r(t);var e=a(14),n=Object(e.a)({},(function(){var s=this,t=s._self._c;return t("ContentSlotsDistributor",{attrs:{"slot-key":s.$parent.slotKey}},[t("h1",{attrs:{id:"一次nginx499状态码排查"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#一次nginx499状态码排查"}},[s._v("#")]),s._v(" 一次Nginx499状态码排查")]),s._v(" "),t("h2",{attrs:{id:"起因"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#起因"}},[s._v("#")]),s._v(" 起因")]),s._v(" "),t("p",[s._v("公司对接某多多，其中有个获取地址抬头接口链路如下")]),s._v(" "),t("p",[s._v("多多 ---http调用--\x3e 我接口 ---\x3e http调用c#地址解析接口")]),s._v(" "),t("p",[s._v("多多要求整个链路时间不超过500ms，否则认为超时。则造成热敏单打印出来无抬头。")]),s._v(" "),t("p",[s._v("当时接口通过ab压测，1000个请求 10个并发的情况下 并无问题出现，基本都是200ms内正常返回。偶现一个较慢情况是因为c#端垃圾回收会回收整个运行环境，导致第一次请求较慢。这个后来已经优化。")]),s._v(" "),t("h2",{attrs:{id:"线上问题"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#线上问题"}},[s._v("#")]),s._v(" 线上问题")]),s._v(" "),t("p",[s._v("上线后，网点反馈打不出抬头。查看日志，发现有超时。")]),s._v(" "),t("p",[s._v("预想的情况是  我接口只负责验签和转发而已。并无耗时逻辑。\n仅仅一次拼参数和一次网络请求，理应是10ms内的处理时间。\n所以整个耗时链路是   多多->我接口的网络耗时+处理耗时（10ms)+我请求c#的网络耗时+c#处理耗时(100ms内)")]),s._v(" "),t("p",[s._v("查看日志发现，有线程上下文切换以及线程阻塞情况。")]),s._v(" "),t("p",[s._v("考虑到有部分服务器比较老旧，可能都是5-10年往上，而且是在虚拟机里跑的服务。且里面还有很多别的应用在跑，而且本身这个代码服务里还有很多别的接口，而且还有个接口一直在被轮询。（不说了，buff叠满了）\n所以认为是产生了线程切换cpu被抢占")]),s._v(" "),t("p",[s._v("第一次优化，将该接口抽取出来，并做一些逻辑简化（如去掉日志切面避免动态代理，去掉System.currentTimestamp避免访问系统内核，简化部分日志）")]),s._v(" "),t("p",[s._v("修改nginx配置，将该服务部署到独立机器，且只有该接口落到新的机器上，这样也能兼容老的接口不受影响（因为要在多多平台配置域名）。")]),s._v(" "),t("p",[s._v("上线后第二天用户仍然反馈有之前抬头未打出情况。\n查看日志，基本耗时都非常快，即便有并发情况，查看几个线程仍然在要求时间内能正常返回。\n"),t("img",{attrs:{src:a(273),alt:"thread"}})]),s._v(" "),t("p",[s._v("遂找到用户具体参数，在整个集群内日志进行搜索，发现未出现该参数，这个情况就有点奇怪了。好像就是多多并未发送请求一样。\n之后找到多多的对接人员，询问具体请求，他排查的情况是出现了Timeout，Read Time out Exception. 让我这边排查下是否是网络抖动或者程序阻塞。")]),s._v(" "),t("p",[s._v("现在的情况是  多多发送了请求，但是我这边并未出现处理日志。难道真的是网络波动了？\n找到生产环境的nginx，查看了下access.log文件，发现当天有900多M，大文件cat肯定不行，用less + awk和sed这些命令分片操作了下，大概如下\n先用less分页定位到了打单前后一分钟的具体时间点，因为可能存在机器时间不一致。所以想法是找那一分钟的日志。\n然后用sed具体时间点查询那一分钟前后的所有日志，这两个时间点必须要存在，否则会刷全日志，导致终端直接卡死。")]),s._v(" "),t("div",{staticClass:"language-shell extra-class"},[t("pre",{pre:!0,attrs:{class:"language-shell"}},[t("code",[t("span",{pre:!0,attrs:{class:"token function"}},[s._v("sed")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token parameter variable"}},[s._v("-n")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token string"}},[s._v("'/2023:16:35:47/,/2023:16:36:47/p'")]),s._v(" access-2023-07-13.log\n")])])]),t("p",[s._v("这一分钟的日志grep该路由")]),s._v(" "),t("div",{staticClass:"language-shell extra-class"},[t("pre",{pre:!0,attrs:{class:"language-shell"}},[t("code",[t("span",{pre:!0,attrs:{class:"token function"}},[s._v("sed")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token parameter variable"}},[s._v("-n")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token string"}},[s._v("'/2023:16:35:47/,/2023:16:36:47/p'")]),s._v(" access-2023-07-13.log "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("|")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token function"}},[s._v("grep")]),s._v(" /route/rule "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("|")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token function"}},[s._v("less")]),s._v("\n")])])]),t("p",[s._v("到这一步其实就已经发现问题了，发现该分钟内有不少的499状态码")]),s._v(" "),t("p",[s._v("到这一步顺便回忆了下一些大日志操作，顺便记录下")]),s._v(" "),t("div",{staticClass:"language-shell extra-class"},[t("pre",{pre:!0,attrs:{class:"language-shell"}},[t("code",[t("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# 将这分钟日志写入快照temp.log文件中")]),s._v("\n"),t("span",{pre:!0,attrs:{class:"token function"}},[s._v("sed")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token parameter variable"}},[s._v("-n")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token string"}},[s._v("'/2023:16:35:47/,/2023:16:36:47/p'")]),s._v(" access-2023-07-13.log "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v(">>")]),s._v(" temp.log\n"),t("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# 根据关键字/route/rule查询前后五行，-A为后五行 -B是前五行 -C为前后")]),s._v("\n"),t("span",{pre:!0,attrs:{class:"token function"}},[s._v("grep")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token parameter variable"}},[s._v("-C")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("5")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token string"}},[s._v("'/route/rule'")]),s._v(" temp.log\n"),t("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# awk根据指定符号或者默认空格和换行进行分割")]),s._v("\n"),t("span",{pre:!0,attrs:{class:"token function"}},[s._v("awk")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token string"}},[s._v("'$9!=200 {print}'")]),s._v(" access.log\n"),t("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# 也可以指定符号，如指定:分割,NR为行号，wc -l 统计行数")]),s._v("\n"),t("span",{pre:!0,attrs:{class:"token function"}},[s._v("awk")]),s._v(" -F: "),t("span",{pre:!0,attrs:{class:"token string"}},[s._v("'$2>200 {print NR}'")]),s._v(" access.log "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("|")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token function"}},[s._v("wc")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token parameter variable"}},[s._v("-l")]),s._v("\n")])])]),t("p",[s._v("到此处，发现499的很多。根据状态码描述了解到是因为客户端设置了readTimeout超时时间，时间内未响应nginx就会直接499并且不继续转发请求了。\n所以具体应用端无日志产生。")]),s._v(" "),t("p",[s._v("我这边也写了测试复现了下，确实会有这种情况")]),s._v(" "),t("p",[s._v("问题定位到了，但是怎么解决，又是个头痛的问题。\n根据上诉链路分析，应用里并无耗时逻辑。分析大概率还是网络波动或者阻塞的情况。")]),s._v(" "),t("p",[s._v("和总监聊了下，因为当前nginx下代理了很多个应用，总体流量相对比较大。\n将该服务的nginx拆出去单独进行代理，先跑两天看看效果会不会好点。")]),s._v(" "),t("p",[s._v("然后又根据情况，完善了下耗时日志，用ab继续进行压测了下。发现转发应用确实没有问题。\n根据ab的耗时，偶尔会出现一条1000ms的请求，但是应用日志的耗时也只有200ms。说明还是在网络io损耗了大量时间。")])])}),[],!1,null,null,null);t.default=n.exports}}]);