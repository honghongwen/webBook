# Kafka相关命令


## 安装

[安装地址](https://kafka.apache.org/downloads)


我这里还是使用的zookeeper启动,我这边没用内置的Kraft，还是走的zookeeper启动。没装最新版，试了下我的springboot版本集成最新版后version有问题。
```shell
tar -xzf kafka_2.12-2.8.0.tgz
```

由于我的端口有冲突，9092已经被gitlab用了。修改下config/server.properties的端口号

```shell
listeners=PLAINTEXT://:9191

advertised.listeners=PLAINTEXT://xxx.xx.xx.xxx:9191
```

启动
```shell
bin/zookeeper-server-start.sh config/zookeeper.properties

bin/kafka-server-start.sh config/server.properties
```


## 相关命令

新建topic
```shell
bin/kafka-topics.sh --create --topic quickstart-events --bootstrap-server localhost:9191
```

查看topic详情
```shell
bin/kafka-topics.sh --describe --topic quickstart-events --bootstrap-server localhost:9191
```

写消息
```shell
bin/kafka-console-producer.sh --topic quickstart-events --bootstrap-server localhost:9191
```

读消息
```shell
bin/kafka-console-consumer.sh --topic quickstart-events --from-beginning --bootstrap-server localhost:9191
```


查看消费者组
```shell
./bin/kafka-consumer-groups.sh --bootstrap-server localhost:9191 --list
```

查看消费者组详情
```shell
./bin/kafka-consumer-groups.sh --bootstrap-server localhost:9191 --describe --group consumerGroupName
```

## 理论

定位
> LinkIn公司采用scala开发的一个多分区、多副本基于zk协调的分布式消息系统，目前定位为一个分布式流式处理平台  

角色
> * 消息系统  
>   * 系统解耦
>   * 冗余存储
>   * 流量消峰
>   * 缓冲
>   * 异步通信
>   * 扩展性
>   * 可恢复性
> * 存储系统
>   * 持久化到磁盘
>   * 数据保留策略为“永久”
>   * 启用主题的日志压缩功能
>   * 多副本
> * 流式处理平台

基本概念
> * Producer
> * Broker - kafka实例
> * Consumer  

---

> * Topic
> * Partition  

kafka消息以topic为单位进行归类，生产者将消息发送到topic，消费者订阅topic进行消费。  

分区为主题下细分概念，分区属于主题，但每个分区的消息都不同，例如对某个topic发10条消息，可能按334这样分布在3个分区中。分区在存储层面可视为一个可追加的log文件，每个消息被追加到分区时会分配一个特定的偏移量offset，这个唯一标识能保证消息在分区内有顺序性。  

之所以设计分区这个概念是因为机器IO瓶颈，如果有多个分区同时消息均匀落在不同分区内，这样可以解决单个机器IO瓶颈的问题。

> * Replica
  
kafka为分区引入了多副本机制，通过增加副本数量提升容灾能力。同一分区的副本保存的是相同的消息，关系为一主多从，leader+follower的模式，leader负责读写，而follower只负责同步冗余，在leader宕机时从follower中重新选举对外提供服务。follower很多时候消息相对于leader会有一定滞后。

consumer使用pull的方式从服务端拉取消息，并且保存消费的具体位置，当消费者宕机重新上线时根据之前保存的消息位置重新拉去消息，这样不会丢失消息。

> * AR - Assigned Replicas  
>   分区内所有副本
> * ISR - In-Sync Replicas  
>   所有与leader副本保持一定程度同步的副本（包括leader副本在内）组成ISR
> * OSR - Out-of-Sync Replicas  
> 与leader副本同步滞后过多的副本（不包括leader副本）组成OSR

这几个概念要结合后面的HW和LEO，了解kafka在性能和一致性之间做出的方案，因为可靠性和性能是个相悖的概念。

这个滞后范围可以通过参数配置，正常情况下要保证所有follower都要与leader保证一定程度内的同步，即AR=ISR，OSR为空。  
leader副本负责维护这个集合，当follower落后太多或失效时，会将follower从ISR转移到OSR集合，同时，如果leader发生故障，只有ISR集合中的follower才有资格被选为leader。

> * HW - High Watermark
> * LEO - Log End Offset  

对于每个分区的日志文件来说，一条消息被写入leader，那么它的offset会+1，初始为0，同时LEO为offset+1,如向leader中写入了9条消息，offset为8，LEO为9，而对于follower来讲，因为它通过拉取leader的消息，所以会有一定的滞后。而对于每个follower也有自己的LEO，比如follower1同步完成，LEO也为9,而follower2同步到了offset 6，那么它的LEO为7。若ISR为3，则follower2是最小的LEO值，那么当前分区的HW也为7，取分区副本isr集合中的最小LEO。而对于消费者来讲，其能消费的消息为0-6的offset区间消息。  

所以对于kafka来讲，它的消息复制既不是完全的同步，也不是单纯的异步，同步要求所有follower完成太影响性能，异步如果